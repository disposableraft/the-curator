{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_cbow(sentences, model=None, alpha=None, work=None, neu1=None, compute_loss=False):\n",
    "        \"\"\"Update CBOW model by training on a sequence of sentences.\n",
    "\n",
    "        Called internally from :meth:`~gensim.models.word2vec.Word2Vec.train`.\n",
    "\n",
    "        Warnings\n",
    "        --------\n",
    "        This is the non-optimized, pure Python version. If you have a C compiler, Gensim\n",
    "        will use an optimized code path from :mod:`gensim.models.word2vec_inner` instead.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : :class:`~gensim.models.word2vec.Word2Vec`\n",
    "            The Word2Vec model instance to train.\n",
    "        sentences : iterable of list of str\n",
    "            The corpus used to train the model.\n",
    "        alpha : float\n",
    "            The learning rate\n",
    "        work : object, optional\n",
    "            Unused.\n",
    "        neu1 : object, optional\n",
    "            Unused.\n",
    "        compute_loss : bool, optional\n",
    "            Whether or not the training loss should be computed in this batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of words in the vocabulary actually used for training (that already existed in the vocabulary\n",
    "            and were not discarded by negative sampling).\n",
    "\n",
    "        \"\"\"\n",
    "        collection = []\n",
    "        result = 0\n",
    "        for sentence in sentences:\n",
    "            # Assume that all words in the sentence are also in the vocabulary\n",
    "            word_vocabs = [ w for w in sentence\n",
    "                # model.wv.vocab[w] for w in sentence if w in model.wv.vocab\n",
    "                # and model.wv.vocab[w].sample_int > model.random.rand() * 2 ** 32\n",
    "                # 'to', 'be', 'or', 'not', 'that', 'is', 'the', 'question'\n",
    "                \n",
    "            ]\n",
    "            for pos, word in enumerate(word_vocabs):\n",
    "                # reduced_window = model.random.randint(model.window)  # `b` in the original word2vec code\n",
    "                reduced_window = 2\n",
    "                # start = max(0, pos - model.window + reduced_window)\n",
    "                start = max(0, pos - 5 + reduced_window)\n",
    "                # window_pos = enumerate(word_vocabs[start:(pos + model.window + 1 - reduced_window)], start)\n",
    "                window_pos = enumerate(word_vocabs[start:(pos + 5 + 1 - reduced_window)], start)\n",
    "                word2_indices = [word2.index for pos2, word2 in window_pos if (word2 is not None and pos2 != pos)]\n",
    "                # l1 = np_sum(model.wv.syn0[word2_indices], axis=0)  # 1 x vector_size\n",
    "                # if word2_indices and model.cbow_mean:\n",
    "                #     l1 /= len(word2_indices)\n",
    "                # train_cbow_pair(model, word, word2_indices, l1, alpha, compute_loss=compute_loss)\n",
    "                \n",
    "                #print(f'{word} --> {[w.__self__ for w in word2_indices]}')\n",
    "                collection.append({word: [w.__self__ for w in word2_indices]})\n",
    "            result += len(word_vocabs)\n",
    "        return result, collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': ['1', '2', '3']},\n",
       " {'1': ['0', '2', '3', '4']},\n",
       " {'2': ['0', '1', '3', '4', '5']},\n",
       " {'3': ['0', '1', '2', '4', '5']},\n",
       " {'4': ['1', '2', '3', '5']},\n",
       " {'5': ['2', '3', '4']}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences2 = [str(x) for x in range(6)]\n",
    "\n",
    "_result, collection = train_batch_cbow([sentences2])\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': ['1', '2', '3']},\n",
       " {'1': ['0', '2', '3', '4']},\n",
       " {'2': ['0', '1', '3', '4', '5']},\n",
       " {'3': ['0', '1', '2', '4', '5']},\n",
       " {'4': ['1', '2', '3', '5']},\n",
       " {'5': ['2', '3', '4']},\n",
       " {'0': ['1', '2', '3']},\n",
       " {'1': ['0', '2', '3', '4']},\n",
       " {'2': ['0', '1', '3', '4', '6']},\n",
       " {'3': ['0', '1', '2', '4', '6']},\n",
       " {'4': ['1', '2', '3', '6']},\n",
       " {'6': ['2', '3', '4']},\n",
       " {'0': ['1', '2', '3']},\n",
       " {'1': ['0', '2', '3', '5']},\n",
       " {'2': ['0', '1', '3', '5', '6']},\n",
       " {'3': ['0', '1', '2', '5', '6']},\n",
       " {'5': ['1', '2', '3', '6']},\n",
       " {'6': ['2', '3', '5']},\n",
       " {'0': ['1', '2', '4']},\n",
       " {'1': ['0', '2', '4', '5']},\n",
       " {'2': ['0', '1', '4', '5', '6']},\n",
       " {'4': ['0', '1', '2', '5', '6']},\n",
       " {'5': ['1', '2', '4', '6']},\n",
       " {'6': ['2', '4', '5']},\n",
       " {'0': ['1', '3', '4']},\n",
       " {'1': ['0', '3', '4', '5']},\n",
       " {'3': ['0', '1', '4', '5', '6']},\n",
       " {'4': ['0', '1', '3', '5', '6']},\n",
       " {'5': ['1', '3', '4', '6']},\n",
       " {'6': ['3', '4', '5']},\n",
       " {'0': ['2', '3', '4']},\n",
       " {'2': ['0', '3', '4', '5']},\n",
       " {'3': ['0', '2', '4', '5', '6']},\n",
       " {'4': ['0', '2', '3', '5', '6']},\n",
       " {'5': ['2', '3', '4', '6']},\n",
       " {'6': ['3', '4', '5']},\n",
       " {'1': ['2', '3', '4']},\n",
       " {'2': ['1', '3', '4', '5']},\n",
       " {'3': ['1', '2', '4', '5', '6']},\n",
       " {'4': ['1', '2', '3', '5', '6']},\n",
       " {'5': ['2', '3', '4', '6']},\n",
       " {'6': ['3', '4', '5']}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "combos = itertools.combinations([str(x) for x in range(7)], 6)\n",
    "\n",
    "result, collection = train_batch_cbow(combos)\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', '1', '2', '3', '4'),\n",
       " ('0', '1', '2', '3', '5'),\n",
       " ('0', '1', '2', '4', '5'),\n",
       " ('0', '1', '3', '4', '5'),\n",
       " ('0', '2', '3', '4', '5'),\n",
       " ('1', '2', '3', '4', '5')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations([str(x) for x in range(6)], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
